---
title: "Generative AI Misinformation Detection (2024-2025) - Final Report"
author: "Mahathi Reddy, Maya Manal France, Nayan Menezes"
date: "December 8, 2025"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

# Load required libraries
library(tidyverse)
library(lubridate)
library(janitor)
library(dplyr)
library(tidytext)
library(knitr)
library(ggplot2)
library(scales)
```

# 1. Introduction

The launch of ChatGPT in November 2022 marked a major shift in how people interact with technology, particularly through the ability to generate detailed text on virtually any topic within seconds. Alongside other generative AI tools such as Claude and Gemini, these systems allow users to produce content—ranging from opinions on politics and sports to music and culture—with minimal independent research. Increasingly, this AI-generated material finds its way onto social media platforms, often without users verifying its accuracy or even recognizing that it was created by an artificial system. In response, platforms such as X have begun flagging posts that may contain AI-generated content in an effort to help users distinguish between human-authored information and automated output.

The dangers of unchecked AI-generated media became especially clear in November 2025, when a deepfake video circulated on social media that altered a 2018 speech by U.S. politician DeAndrea Salvador to make it appear as though she was addressing low-income communities in São Paulo, Brazil. The manipulated video was later revealed to have been used in a marketing campaign by Whirlpool's Brazilian advertising agency. As generative models continue to advance, distinguishing between authentic and fabricated content is becoming increasingly difficult, raising serious concerns about the potential consequences of AI-driven misinformation on individuals' reputations, careers, and public trust.

The aim of this study is to identify patterns in how AI-generated posts are created, where they appear online, and what types of content they contain. By analyzing these trends, we seek to better equip individuals to navigate the increasingly complex and confusing information landscape shaped by social media and artificial intelligence. This data set is a simulation of current news and content ratios as found on Kaggle. 

## Research Questions

To accomplish this goal, we established 9 research questions that this dataset allows us to answer:

1. Which social media platform is most prone to AI-generated content?
2. How long are posts that are typically flagged as AI-generated compared to other model signatures?
3. Does AI-generated content receive different sentiment scores compared to human posts?
4. Are misinformation posts more likely to come from AI-generated content compared to legitimate posts?
5. Do misinformation posts show higher toxicity levels than legitimate posts?
6. Which country contributes the most misinformation content, and how does that compare to legitimate content?
7. How does engagement (likes, shares, interactions) differ between misinformation and legitimate posts?
8. Are certain sentiment trends (negative, neutral, positive) more common in misinformation posts?
9. Do verified users spread misinformation at a higher or lower rate than unverified users?

# 2. Data

## 2.1. Load Data

```{r load_data}
df <- read_csv("generative_ai_misinformation_dataset.csv")
```

## 2.2. Data Cleaning

```{r clean_data}
# Standardize column names
df <- df %>% clean_names()

# Remove rows with impossible values
df <- df %>%
  filter(
    between(sentiment_score, -1, 1),
    between(toxicity_score, 0, 1),
    between(detected_synthetic_score, 0, 1),
    between(embedding_sim_to_facts, 0, 1),
    readability_score >= 0
  ) %>%
  drop_na(is_misinformation)

# Standardize text formatting and convert to factors
df <- df %>%
  mutate(
    platform = str_to_title(platform),
    country = str_to_title(country),
    city = str_to_title(city),
    factcheck_verdict = str_to_lower(factcheck_verdict),
    date = as.Date(date),
    platform = as.factor(platform),
    is_misinformation = factor(is_misinformation, 
                                levels = c(0, 1), 
                                labels = c("Legitimate", "Misinformation")),
    ai_generated = factor(ifelse(model_signature == "GPT-like", 
                                 "AI-generated", 
                                 "Non-AI / Unknown"),
                         levels = c("AI-generated", "Non-AI / Unknown")),
    sentiment_category = factor(case_when(
      sentiment_score <= -0.2 ~ "Negative",
      sentiment_score >= 0.2 ~ "Positive",
      TRUE ~ "Neutral"
    ), levels = c("Negative", "Neutral", "Positive"))
  )
```

## 2.3. Dataset Overview

```{r dataset_info}
cat("Number of rows:", nrow(df), "\n")
cat("Number of columns:", ncol(df), "\n")
cat("Missing values:", sum(is.na(df)), "\n")
cat("Duplicate post IDs:", sum(duplicated(df$post_id)), "\n")
```

### Variables

- **Post information:** platform, text content, timestamp, location
- **Content metrics:** text length, readability score, sentiment, toxicity
- **AI detection:** model signature (GPT-like, human, unknown), synthetic score
- **Author info:** follower count, verification status
- **Target variable:** is_misinformation (0 = legitimate, 1 = misinformation)

### Data Distribution

```{r data_distribution, fig.height=5}
# Misinformation distribution
ggplot(df, aes(x = is_misinformation, fill = is_misinformation)) +
  geom_bar() +
  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5) +
  scale_fill_manual(values = c("Legitimate" = "#4CAF50", "Misinformation" = "#F44336")) +
  labs(title = "Distribution of Misinformation vs Legitimate Posts", 
       x = "Post Type", y = "Count") +
  theme_minimal() +
  theme(legend.position = "none", plot.title = element_text(face = "bold"))
```

**Finding:** Out of 500 posts, 259 (51.8%) are misinformation and 241 (48.2%) are legitimate—a fairly balanced dataset.

```{r model_signature_dist, fig.height=5}
# Model signature distribution
ggplot(df, aes(x = model_signature, fill = model_signature)) +
  geom_bar() +
  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5) +
  labs(title = "Distribution of Model Signatures", 
       x = "Model Signature", y = "Count") +
  theme_minimal() +
  theme(legend.position = "none", plot.title = element_text(face = "bold"))
```

**Finding:** About one-third of posts (157) are detected as "GPT-like" (AI-generated), one-third are human-written (174), and one-third are unknown (169).

### Summary Statistics

```{r summary_stats}
summary_vars <- df %>% 
  select(text_length, sentiment_score, toxicity_score, 
         detected_synthetic_score, engagement)

summary(summary_vars)
```

# 3. Research Findings

## Question 1: Platform Susceptibility to AI-Generated Content

**Which social media platform is most prone to AI-generated content?**

```{r q1_analysis}
# Contingency table
platform_table <- table(df$platform, df$model_signature == "GPT-like")
colnames(platform_table) <- c("Human/Unknown", "AI-Generated")
kable(platform_table, caption = "Posts by Platform and Content Type")

# Calculate proportions
platform_props <- df %>%
  group_by(platform) %>%
  summarise(
    Total = n(),
    AI_Posts = sum(model_signature == "GPT-like"),
    AI_Percentage = (AI_Posts / Total) * 100
  )
kable(platform_props, digits = 1, caption = "AI-Generated Content Rate by Platform")

# Chi-square test
chi_test_platform <- chisq.test(platform_table)
cramers_v_platform <- sqrt(chi_test_platform$statistic / 
                           (sum(platform_table) * (min(dim(platform_table)) - 1)))

cat("Chi-square statistic:", round(chi_test_platform$statistic, 4), "\n")
cat("P-value:", format.pval(chi_test_platform$p.value, digits = 4), "\n")
cat("Cramér's V:", round(cramers_v_platform, 4), "\n")
```

```{r q1_viz, fig.height=6}
platform_viz <- df %>%
  mutate(AI_Type = ifelse(model_signature == "GPT-like", "AI-Generated", "Human/Unknown")) %>%
  group_by(platform, AI_Type) %>%
  summarise(Count = n(), .groups = "drop") %>%
  group_by(platform) %>%
  mutate(Percentage = (Count / sum(Count)) * 100)

ggplot(platform_viz, aes(x = platform, y = Percentage, fill = AI_Type)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8, width = 0.7) +
  geom_text(aes(label = paste0(round(Percentage, 1), "%")), 
            position = position_dodge(width = 0.7), vjust = -0.5, size = 3.5) +
  scale_fill_manual(values = c("Human/Unknown" = "#4CAF50", "AI-Generated" = "#F44336")) +
  labs(title = "AI-Generated Content by Platform",
       x = "Platform", y = "Percentage of Posts (%)", fill = "Content Type") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")
```

**Key Findings:**

- Most AI-prone: **`r platform_props %>% arrange(desc(AI_Percentage)) %>% slice(1) %>% pull(platform)`** (`r round(platform_props %>% arrange(desc(AI_Percentage)) %>% slice(1) %>% pull(AI_Percentage), 1)`%)
- Least AI-prone: **`r platform_props %>% arrange(AI_Percentage) %>% slice(1) %>% pull(platform)`** (`r round(platform_props %>% arrange(AI_Percentage) %>% slice(1) %>% pull(AI_Percentage), 1)`%)
- Statistical significance: **`r ifelse(chi_test_platform$p.value < 0.05, "YES", "NO")`** (p = `r round(chi_test_platform$p.value, 4)`)

---

## Question 2: Post Length and AI Content

**How long are posts that are typically flagged as AI-generated?**

```{r q2_analysis}
length_summary <- df %>%
  group_by(model_signature) %>%
  summarise(
    Count = n(),
    Mean = mean(text_length),
    Median = median(text_length),
    SD = sd(text_length)
  )
kable(length_summary, digits = 1, caption = "Text Length by Model Signature")

# Statistical test
ai_lengths <- df %>% filter(model_signature == "GPT-like") %>% pull(text_length)
human_lengths <- df %>% filter(model_signature != "GPT-like") %>% pull(text_length)
length_test <- wilcox.test(ai_lengths, human_lengths)

cat("Wilcoxon test p-value:", format.pval(length_test$p.value, digits = 4), "\n")
```

```{r q2_viz, fig.height=6}
ggplot(df, aes(x = model_signature, y = text_length, fill = model_signature)) +
  geom_boxplot(alpha = 0.8) +
  labs(title = "Post Length by Content Source",
       x = "Content Source", y = "Post Length (Characters)") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "none")
```

**Key Findings:**

- AI-generated posts: **`r round(mean(ai_lengths), 1)`** characters (mean)
- Human posts: **`r round(mean(human_lengths), 1)`** characters (mean)
- Statistical significance: **`r ifelse(length_test$p.value < 0.05, "YES", "NO")`** (p = `r round(length_test$p.value, 4)`)

---

## Question 3: AI Content and Sentiment

**Does AI-generated content have different sentiment scores?**

```{r q3_analysis}
sentiment_summary <- df %>%
  group_by(model_signature) %>%
  summarise(
    Count = n(),
    Mean = mean(sentiment_score),
    Median = median(sentiment_score),
    SD = sd(sentiment_score)
  )
kable(sentiment_summary, digits = 2, caption = "Sentiment by Content Source")

ai_sentiment <- df %>% filter(model_signature == "GPT-like") %>% pull(sentiment_score)
human_sentiment <- df %>% filter(model_signature == "human") %>% pull(sentiment_score)
sentiment_test <- wilcox.test(ai_sentiment, human_sentiment)

cat("Wilcoxon test p-value:", format.pval(sentiment_test$p.value, digits = 4), "\n")
```

```{r q3_viz, fig.height=6}
ggplot(df, aes(x = model_signature, y = sentiment_score, fill = model_signature)) +
  geom_boxplot(alpha = 0.8) +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 3, color = "red") +
  labs(title = "Sentiment Scores by Content Source",
       x = "Content Source", y = "Sentiment Score") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "none")
```

**Key Findings:**

- AI sentiment: **`r round(mean(ai_sentiment), 2)`** (mean)
- Human sentiment: **`r round(mean(human_sentiment), 2)`** (mean)
- Statistical significance: **`r ifelse(sentiment_test$p.value < 0.05, "YES", "NO")`** (p = `r round(sentiment_test$p.value, 4)`)

---

## Question 4: AI Content and Misinformation

**Are misinformation posts more likely to be AI-generated?**

```{r q4_analysis}
ai_table <- table(df$ai_generated, df$is_misinformation)
kable(ai_table, caption = "Posts by AI Status and Misinformation")

ai_props <- df %>%
  group_by(ai_generated, is_misinformation) %>%
  summarise(Count = n(), .groups = "drop") %>%
  group_by(ai_generated) %>%
  mutate(Percentage = 100 * Count / sum(Count))
kable(ai_props, digits = 1, caption = "Misinformation Rate by AI Status")

chi_ai <- chisq.test(ai_table)
cat("Chi-square p-value:", format.pval(chi_ai$p.value, digits = 4), "\n")
```

```{r q4_viz, fig.height=6}
ggplot(ai_props, aes(x = ai_generated, y = Percentage, fill = is_misinformation)) +
  geom_col(position = "dodge", alpha = 0.85, width = 0.7) +
  geom_text(aes(label = paste0(round(Percentage, 1), "%")),
            position = position_dodge(width = 0.7), vjust = -0.4, size = 4) +
  scale_fill_manual(values = c("Legitimate" = "#4CAF50", "Misinformation" = "#F44336")) +
  labs(title = "Misinformation vs Legitimate Posts by AI Status",
       x = "Content Type", y = "Percentage", fill = "Post Type") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")
```

**Key Findings:**

```{r q4_findings}
ai_misinfo_rate <- ai_props %>% 
  filter(ai_generated == "AI-generated", is_misinformation == "Misinformation") %>% 
  pull(Percentage)
non_ai_misinfo_rate <- ai_props %>% 
  filter(ai_generated == "Non-AI / Unknown", is_misinformation == "Misinformation") %>% 
  pull(Percentage)
```

- AI-generated misinformation rate: **`r round(ai_misinfo_rate, 1)`%**
- Non-AI misinformation rate: **`r round(non_ai_misinfo_rate, 1)`%**
- Statistical significance: **`r ifelse(chi_ai$p.value < 0.05, "YES", "NO")`** (p = `r round(chi_ai$p.value, 4)`)

---

## Question 5: Toxicity Levels

**Do misinformation posts show higher toxicity?**

```{r q5_analysis}
toxicity_summary <- df %>%
  group_by(is_misinformation) %>%
  summarise(
    Mean = mean(toxicity_score),
    Median = median(toxicity_score),
    SD = sd(toxicity_score),
    Min = min(toxicity_score),
    Max = max(toxicity_score),
    Count = n()
  )
kable(toxicity_summary, digits = 3, caption = "Toxicity by Post Type")

t_test_toxicity <- t.test(toxicity_score ~ is_misinformation, data = df)
cat("T-test p-value:", format.pval(t_test_toxicity$p.value, digits = 4), "\n")
cat("Mean difference:", round(diff(t_test_toxicity$estimate), 4), "\n")
```

```{r q5_viz, fig.height=6}
ggplot(df, aes(x = is_misinformation, y = toxicity_score, fill = is_misinformation)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(alpha = 0.2, width = 0.2, size = 1) +
  scale_fill_manual(values = c("Legitimate" = "#4CAF50", "Misinformation" = "#F44336")) +
  labs(title = "Toxicity: Misinformation vs Legitimate Posts",
       x = "Post Type", y = "Toxicity Score (0-1)") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "none")
```

**Key Findings:**

- Legitimate toxicity: **`r round(toxicity_summary$Mean[1], 3)`**
- Misinformation toxicity: **`r round(toxicity_summary$Mean[2], 3)`**
- Statistical significance: **`r ifelse(t_test_toxicity$p.value < 0.05, "YES", "NO")`** (p = `r round(t_test_toxicity$p.value, 4)`)

---

## Question 6: Country Analysis

**Which country contributes the most misinformation?**

```{r q6_analysis}
country_summary <- df %>%
  group_by(country, is_misinformation) %>%
  summarise(Count = n(), .groups = "drop") %>%
  group_by(country) %>%
  mutate(Percentage = 100 * Count / sum(Count))
kable(country_summary, digits = 1, caption = "Misinformation by Country")

country_table <- table(df$country, df$is_misinformation)
chi_country <- chisq.test(country_table)
cat("Chi-square p-value:", format.pval(chi_country$p.value, digits = 4), "\n")
```

```{r q6_viz, fig.height=6}
misinfo_by_country <- country_summary %>% filter(is_misinformation == "Misinformation")

ggplot(misinfo_by_country, aes(x = reorder(country, -Percentage), y = Percentage)) +
  geom_col(alpha = 0.85, width = 0.7, fill = "#F44336") +
  geom_text(aes(label = paste0(round(Percentage, 1), "%")), vjust = -0.4, size = 4) +
  labs(title = "Misinformation Rate by Country",
       x = "Country", y = "% of Country's Posts") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"))
```

**Key Findings:**

```{r q6_findings}
top_country <- misinfo_by_country %>% arrange(desc(Percentage)) %>% slice(1)
```

- Highest misinformation rate: **`r top_country$country`** (`r round(top_country$Percentage, 1)`%)
- Statistical significance: **`r ifelse(chi_country$p.value < 0.05, "YES", "NO")`** (p = `r round(chi_country$p.value, 4)`)

---

## Question 7: Engagement Differences

**How does engagement differ between misinformation and legitimate posts?**

```{r q7_analysis}
engagement_summary <- df %>%
  group_by(is_misinformation) %>%
  summarise(
    Mean = mean(engagement),
    Median = median(engagement),
    SD = sd(engagement),
    Min = min(engagement),
    Max = max(engagement),
    Count = n()
  )
kable(engagement_summary, digits = 1, caption = "Engagement by Post Type")

wilcox_test_engagement <- wilcox.test(engagement ~ is_misinformation, data = df)
cat("Wilcoxon test p-value:", format.pval(wilcox_test_engagement$p.value, digits = 4), "\n")
```

```{r q7_viz, fig.height=6}
ggplot(df, aes(x = is_misinformation, y = engagement, fill = is_misinformation)) +
  geom_boxplot(alpha = 0.7, outlier.shape = NA) +
  geom_jitter(alpha = 0.3, width = 0.2, size = 1.5) +
  scale_fill_manual(values = c("Legitimate" = "#4CAF50", "Misinformation" = "#F44336")) +
  scale_y_continuous(labels = comma) +
  labs(title = "Engagement: Misinformation vs Legitimate Posts",
       x = "Post Type", y = "Engagement") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "none")
```

**Key Findings:**

- Legitimate median engagement: **`r comma(round(engagement_summary$Median[1], 0))`**
- Misinformation median engagement: **`r comma(round(engagement_summary$Median[2], 0))`**
- Statistical significance: **`r ifelse(wilcox_test_engagement$p.value < 0.05, "YES", "NO")`** (p = `r round(wilcox_test_engagement$p.value, 4)`)

---

## Question 8: Sentiment Trends

**Are certain sentiments more common in misinformation?**

```{r q8_analysis}
sentiment_cat_summary <- df %>%
  group_by(sentiment_category, is_misinformation) %>%
  summarise(Count = n(), .groups = "drop") %>%
  group_by(sentiment_category) %>%
  mutate(Percentage = 100 * Count / sum(Count))
kable(sentiment_cat_summary, digits = 1, caption = "Misinformation by Sentiment")

sentiment_table <- table(df$sentiment_category, df$is_misinformation)
chi_sentiment <- chisq.test(sentiment_table)
cat("Chi-square p-value:", format.pval(chi_sentiment$p.value, digits = 4), "\n")
```

```{r q8_viz, fig.height=6}
ggplot(sentiment_cat_summary, aes(x = sentiment_category, y = Percentage, 
                                   fill = is_misinformation)) +
  geom_col(position = "dodge", alpha = 0.85, width = 0.7) +
  geom_text(aes(label = paste0(round(Percentage, 1), "%")),
            position = position_dodge(width = 0.7), vjust = -0.4, size = 4) +
  scale_fill_manual(values = c("Legitimate" = "#4CAF50", "Misinformation" = "#F44336")) +
  labs(title = "Misinformation by Sentiment Category",
       x = "Sentiment", y = "Percentage", fill = "Post Type") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")
```

**Key Findings:**

```{r q8_findings}
top_sentiment_misinfo <- sentiment_cat_summary %>%
  filter(is_misinformation == "Misinformation") %>%
  arrange(desc(Percentage)) %>%
  slice(1)
```

- Highest misinformation sentiment: **`r top_sentiment_misinfo$sentiment_category`** (`r round(top_sentiment_misinfo$Percentage, 1)`%)
- Statistical significance: **`r ifelse(chi_sentiment$p.value < 0.05, "YES", "NO")`** (p = `r round(chi_sentiment$p.value, 4)`)

---

## Question 9: Verified Users

**Do verified users spread less misinformation?**

```{r q9_analysis}
verification_table <- table(df$author_verified, df$is_misinformation)
rownames(verification_table) <- c("Unverified", "Verified")
kable(verification_table, caption = "Posts by Verification Status")

verification_props <- df %>%
  group_by(author_verified, is_misinformation) %>%
  summarise(Count = n(), .groups = 'drop') %>%
  group_by(author_verified) %>%
  mutate(Percentage = 100 * Count / sum(Count))

misinfo_rates <- verification_props %>%
  filter(is_misinformation == "Misinformation") %>%
  mutate(Status = ifelse(author_verified == 1, "Verified", "Unverified")) %>%
  select(Status, Percentage)
kable(misinfo_rates, digits = 1, caption = "Misinformation Rate by Verification")

chi_verify <- chisq.test(verification_table)
cat("Chi-square p-value:", format.pval(chi_verify$p.value, digits = 4), "\n")
```

```{r q9_viz, fig.height=6}
verification_viz <- df %>%
  mutate(Verified = factor(author_verified, levels = c(0, 1), 
                          labels = c("Unverified", "Verified"))) %>%
  group_by(Verified, is_misinformation) %>%
  summarise(Count = n(), .groups = 'drop') %>%
  group_by(Verified) %>%
  mutate(Percentage = 100 * Count / sum(Count))

ggplot(verification_viz, aes(x = Verified, y = Percentage, fill = is_misinformation)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8, width = 0.7) +
  geom_text(aes(label = paste0(round(Percentage, 1), "%")),
            position = position_dodge(width = 0.7), vjust = -0.5, size = 4) +
  scale_fill_manual(values = c("Legitimate" = "#4CAF50", "Misinformation" = "#F44336")) +
  labs(title = "Misinformation by Verification Status",
       x = "User Status", y = "Percentage", fill = "Post Type") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"), legend.position = "bottom")
```

**Key Findings:**

```{r q9_findings}
verified_rate <- misinfo_rates %>% filter(Status == "Verified") %>% pull(Percentage)
unverified_rate <- misinfo_rates %>% filter(Status == "Unverified") %>% pull(Percentage)
```

- Verified users: **`r round(verified_rate, 1)`%** misinformation rate
- Unverified users: **`r round(unverified_rate, 1)`%** misinformation rate
- Statistical significance: **`r ifelse(chi_verify$p.value < 0.05, "YES", "NO")`** (p = `r round(chi_verify$p.value, 4)`)

---

# 4. Summary of Findings

```{r summary_table}
summary_results <- data.frame(
  Question = c(
    "Q1: Platform susceptibility",
    "Q2: Post length (AI vs human)",
    "Q3: Sentiment (AI vs human)",
    "Q4: AI & misinformation",
    "Q5: Toxicity levels",
    "Q6: Country differences",
    "Q7: Engagement levels",
    "Q8: Sentiment trends",
    "Q9: Verified users"
  ),
  Significant = c(
    ifelse(chi_test_platform$p.value < 0.05, "Yes", "No"),
    ifelse(length_test$p.value < 0.05, "Yes", "No"),
    ifelse(sentiment_test$p.value < 0.05, "Yes", "No"),
    ifelse(chi_ai$p.value < 0.05, "Yes", "No"),
    ifelse(t_test_toxicity$p.value < 0.05, "Yes", "No"),
    ifelse(chi_country$p.value < 0.05, "Yes", "No"),
    ifelse(wilcox_test_engagement$p.value < 0.05, "Yes", "No"),
    ifelse(chi_sentiment$p.value < 0.05, "Yes", "No"),
    ifelse(chi_verify$p.value < 0.05, "Yes", "No")
  ),
  P_Value = c(
    round(chi_test_platform$p.value, 4),
    round(length_test$p.value, 4),
    round(sentiment_test$p.value, 4),
    round(chi_ai$p.value, 4),
    round(t_test_toxicity$p.value, 4),
    round(chi_country$p.value, 4),
    round(wilcox_test_engagement$p.value, 4),
    round(chi_sentiment$p.value, 4),
    round(chi_verify$p.value, 4)
  )
)

kable(summary_results, caption = "Summary of All Statistical Tests")
```

# 5