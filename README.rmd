---
title: "Generative AI Misinformation Detection (2024-2025) - Final Report"
author: "Mahathi Reddy, Maya Manal France, Nayan Menezes"
date: "Dec. 8, 2025"
output: html_document
---

# 1. Introduction

The launch of ChatGPT in November 2022 marked a major shift in how people interact with technology, particularly through the ability to generate detailed text on virtually any topic within seconds. Alongside other generative AI tools such as Claude and Gemini, these systems allow users to produce content—ranging from opinions on politics and sports to music and culture — with minimal independent research. Increasingly, this AI-generated material finds its way onto social media platforms, often without users verifying its accuracy or even recognizing that it was created by an artificial system. In response, platforms such as X have begun flagging posts that may contain AI-generated content in an effort to help users distinguish between human-authored information and automated output.

The dangers of unchecked AI-generated media became especially clear in November 2025, when a deepfake video circulated on social media that altered a 2018 speech by U.S. politician DeAndrea Salvador to make it appear as though she was addressing low-income communities in São Paulo, Brazil. The manipulated video was later revealed to have been used in a marketing campaign by Whirlpool’s Brazilian advertising agency. As generative models continue to advance, distinguishing between authentic and fabricated content is becoming increasingly difficult, raising serious concerns about the potential consequences of AI-driven misinformation on individuals’ reputations, careers, and public trust.

The aim of this study is to identify patterns in how AI-generated posts are created, where they appear online, and what types of content they contain. By analyzing these trends, we seek to better equip individuals to navigate the increasingly complex and confusing information landscape shaped by social media and artificial intelligence.

To accomplish this goal, we laid out a list of 9 questions which this dataset will allow us to answer:

  1. Which social media platform is most prone to AI-generated content?
  
  2. How long are posts that are typically flagged as AI-generated compared to other model sigantures?
  
  3. Does AI-generated content receive different sentiment scores compared to human posts?
  
  4. Are misinformation posts more likely to come from AI-generated content compared to legitimate posts?
  
  5. Do misinformation posts show higher toxicity levels than legitimate posts?
  
  6. Which country contributes the most misinformation content, and how does that compare to legitimate content?
  
  7. How does engagement (likes, shares, interactions) differ between misinformation and legitimate posts?
  
  8. Are certain sentiment trends (negative, neutral, positive) more common in misinformation posts?
  
  9. Do verified users spread misinformation at a higher or lower rate than unverified users?

# 2. Data

### 2.1. Load Data and Libraries
```{r setup, echo=TRUE, results="hide", message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

library(tidyverse)
library(lubridate)
library(janitor)
library(dplyr)
library(tidytext)
library(knitr)

df <- read_csv("generative_ai_misinformation_dataset.csv")
```

```{r load}
# Show first few rows
head(df)
```
### 2.2 Data Cleaning

This data cleaning step converts spaces in column names to underscores, forces them to be lowercase, and removes any special characters
for better use in data manipulation. 

```{r}
df <- df %>% clean_names()
```


This data cleaning step removes any rows that might have impossible values do not belong within certain bounds outlined on the dataset's website. 

```{r}
df <- df %>%
  filter(
    between(sentiment_score, -1, 1),
    between(toxicity_score, 0, 1),
    between(detected_synthetic_score, 0, 1),
    between(embedding_sim_to_facts, 0, 1),
    readability_score >= 0
  )

```

This data cleaning step removes any rows that do not have a determination on whether the post was created by generative AI.
```{r}
df <- df %>%
  drop_na(is_misinformation)
```

This data cleaning step removes any categorical text inconsistencies, and converts important variables into factors for better data manipulation.

```{r}
df <- df %>%
  mutate(
    platform = str_to_title(platform),
    country = str_to_title(country),
    city = str_to_title(city),
    factcheck_verdict = str_to_lower(factcheck_verdict)
  )

df$date <- as.Date(df$date)
df$platform <- as.factor(df$platform)
df$is_misinformation <- factor(df$is_misinformation, 
                                levels = c(0, 1), 
                                labels = c("Legitimate", "Misinformation"))
```

### 2.3 Dataset Information

#### 2.3.1 Number of rows, columns, and null rows
```{r description}
# Basic information
cat("Number of rows:", nrow(df), "\n")
cat("Number of columns:", ncol(df), "\n")
cat("Missing values:", sum(is.na(df)), "\n")
```

#### 2.3.2 Variables

- **Post information:** platform, text content, timestamp, location
- **Content metrics:** text length, readability score, sentiment, toxicity
- **AI detection:** model signature (GPT-like, human, unknown), synthetic score
- **Author info:** follower count, verification status
- **Target variable:** is_misinformation (0 = legitimate, 1 = misinformation)

#### 2.3.3 Basic Data Summaries

How much misinformation is there?

```{r misinformation}
# Count misinformation vs legitimate
table(df$is_misinformation)

# Make a bar plot
ggplot(df, aes(x = is_misinformation, fill = is_misinformation)) +
  geom_bar() +
  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5) +
  scale_fill_manual(values = c("Legitimate" = "green", "Misinformation" = "red")) +
  labs(title = "Misinformation vs Legitimate Posts", 
       x = "Type", y = "Count") +
  theme_minimal() +
  theme(legend.position = "none")
```

**Finding:** Out of 500 posts, 259 (51.8%) are misinformation and 241 (48.2%) are legitimate. This is a fairly balanced dataset, which is good for building predictive models.


How much content is AI-generated?

```{r model_signature}
# Count by model signature
table(df$model_signature)

# Bar plot
ggplot(df, aes(x = model_signature, fill = model_signature)) +
  geom_bar() +
  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5) +
  labs(title = "AI Detection: Model Signatures", 
       x = "Model Signature", y = "Count") +
  theme_minimal() +
  theme(legend.position = "none")
```

**Finding:** About one-third of posts (157) are detected as "GPT-like" (AI-generated), one-third are human-written (174), and one-third are unknown (169). This suggests AI-generated content is a significant presence in social media.

Which countries are represented?

```{r countries}
# Count by country
table(df$country)

# Bar plot
ggplot(df, aes(x = country, fill = country)) +
  geom_bar() +
  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5) +
  labs(title = "Posts by Country", x = "Country", y = "Count") +
  theme_minimal() +
  theme(legend.position = "none")
```

**Finding:** The dataset covers 5 countries with relatively equal representation (~86-113 posts each). This geographic diversity means our findings can potentially apply across different regions.

Which platforms have the most posts?

```{r platforms}
# Count by platform
table(df$platform)

# Bar plot
ggplot(df, aes(x = platform, fill = platform)) +
  geom_bar() +
  geom_text(stat = 'count', aes(label = after_stat(count)), vjust = -0.5) +
  labs(title = "Posts by Platform", x = "Platform", y = "Count") +
  theme_minimal() +
  theme(legend.position = "none")
```

**Finding:** Posts are fairly evenly distributed across all four platforms. Twitter has slightly more posts (129), while the others have around 121-26 posts each. This means our dataset isn't biased toward any single platform.

#### 2.3.4 Summary Statistics for Key Numbers

```{r summary_stats}
# Select important numerical variables
summary_vars <- df %>% 
  select(text_length, sentiment_score, toxicity_score, 
         detected_synthetic_score, engagement)

# Get summary statistics
summary(summary_vars)
```

**What these numbers mean:**

- **Text length:** Posts average 150 characters (range: 20-280). Most posts are relatively short.
- **Sentiment score:** Ranges from -1 (very negative) to 1 (very positive). Average is near 0, meaning posts are generally neutral.
- **Toxicity score:** Ranges from 0 (not toxic) to 1 (very toxic). Average is 0.49, suggesting moderate toxicity overall.
- **Synthetic score:** Higher scores mean more likely to be AI-generated. Wide range suggests varying confidence in detection.
- **Engagement:** Highly variable (4 to 9,977), meaning some posts go viral while others get little attention.

#### Data Quality Check
```{r quality_check}
cat("Data Quality Summary:\n")
cat("- Total records:", nrow(df), "\n")
cat("- Missing values:", sum(is.na(df)), "\n")
cat("- Duplicate post IDs:", sum(duplicated(df$post_id)), "\n")
```

**Quality notes:** The dataset is clean with no missing values or duplicates. All 500 records are complete and ready for use.

# 3. Findings

# Research Question 1: Platform Susceptibility to AI-Generated Content

**Question:** Which social media platform is most prone to AI-generated content?

## Contingency Table

```{r q1_table}
# Create contingency table
platform_table <- table(df$platform, df$model_signature == "GPT-like")
colnames(platform_table) <- c("Human", "AI-Generated")

kable(platform_table, caption = "Posts by Platform and Content Type")
```

## AI-Generated Content Rates Table

```{r q1_rates}
# Calculate proportions
platform_props <- df %>%
  group_by(platform) %>%
  summarise(
    Total = n(),
    AI_Posts = sum(model_signature == "GPT-like"),
    AI_Percentage = (AI_Posts / Total) * 100
  )

kable(platform_props, digits = 1, caption = "AI-Generated Content Rate by Platform")
```

## Statistical Test
```{r q1_test}
# Chi-square test
chi_test_platform <- chisq.test(platform_table)

cat("Chi-Square Test of Independence\n")
cat("Chi-square statistic:", round(chi_test_platform$statistic, 4), "\n")
cat("Degrees of freedom:", chi_test_platform$parameter, "\n")
cat("P-value:", format.pval(chi_test_platform$p.value, digits = 4), "\n")

# Calculate effect size (Cramér's V)
cramers_v_platform <- sqrt(
  chi_test_platform$statistic / 
  (sum(platform_table) * (min(dim(platform_table)) - 1))
)

cat("Effect size (Cramér's V):", round(cramers_v_platform, 4), "\n")

if (chi_test_platform$p.value < 0.05) {
  cat("\n✓ Result: There IS a statistically significant association between\n")
  cat("  platform and likelihood of AI-generated content (p < 0.05)\n")
} else {
  cat("\n✗ Result: There is NO statistically significant association between\n")
  cat("  platform and likelihood of AI-generated content (p >= 0.05)\n")
}
```

## Visualization 1: Percentage Bar Chart

```{r q1_viz1, fig.height=7}
platform_viz <- df %>%
  mutate(AI_Type = ifelse(model_signature == "GPT-like", 
                          "AI-Generated", "Human")) %>%
  group_by(platform, AI_Type) %>%
  summarise(Count = n(), .groups = "drop") %>%
  group_by(platform) %>%
  mutate(Percentage = (Count / sum(Count)) * 100)

p3 <- ggplot(platform_viz, aes(x = platform, y = Percentage, fill = AI_Type)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8, width = 0.7) +
  geom_text(aes(label = paste0(round(Percentage, 1), "%")), 
            position = position_dodge(width = 0.7), 
            vjust = -0.5, fontface = "bold", size = 4) +
  scale_fill_manual(values = c("Human" = "#4CAF50", 
                                "AI-Generated" = "#F44336")) +
  labs(title = "AI-Generated Content by Platform",
       subtitle = "Percentage of posts that are AI-generated vs human",
       x = "Platform",
       y = "Percentage of Posts (%)",
       fill = "Post Type") +
  theme_minimal(base_size = 12) +
  theme(plot.title = element_text(face = "bold", size = 16),
        plot.subtitle = element_text(size = 12),
        legend.position = "bottom",
        legend.title = element_text(face = "bold"))

print(p3)
```

##  Visualization 2: Raw Counts Bar Chart
```{r q1_viz2, fig.height=6}
p3b <- ggplot(platform_viz, aes(x = platform, y = Count, fill = AI_Type)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8, width = 0.7) +
  geom_text(aes(label = Count), 
            position = position_dodge(width = 0.7), 
            vjust = -0.5, fontface = "bold", size = 4) +
  scale_fill_manual(values = c("Human" = "#4CAF50", 
                                "AI-Generated" = "#F44336")) +
  labs(title = "Raw Counts: AI vs Human Posts by Platform",
       x = "Platform",
       y = "Number of Posts",
       fill = "Post Type") +
  theme_minimal(base_size = 12) +
  theme(plot.title = element_text(face = "bold", size = 16),
        legend.position = "bottom",
        legend.title = element_text(face = "bold"))

print(p3b)
```

**Key Findings**
```{r q1_findings, echo=FALSE}
most_prone <- platform_props %>%
  arrange(desc(AI_Percentage)) %>%
  slice(1)

least_prone <- platform_props %>%
  arrange(AI_Percentage) %>%
  slice(1)
```

- **Most AI-prone platform:** `r most_prone$platform`  
  (`r round(most_prone$AI_Percentage, 1)`% of posts are AI-generated)

- **Least AI-prone platform:** `r least_prone$platform`  
  (`r round(least_prone$AI_Percentage, 1)`% of posts are AI-generated)

- **Statistical significance:**  
  `r ifelse(chi_test_platform$p.value < 0.05, "YES", "NO")`  
  *(p = `r round(chi_test_platform$p.value, 4)`)*

- **Effect size (Cramér’s V):** `r round(cramers_v_platform, 4)`

# Research Question 2: Post Length and AI-Generated Content

**Question:** How long are posts that are typically flagged as AI-generated compared to other model signatures?

## AI-Generated post length table

```{r q2_table}
length_summary <- df %>%
  group_by(model_signature) %>%
  summarise(
    Count = n(),
    Mean_Length = mean(text_length, na.rm = TRUE),
    Median_Length = median(text_length, na.rm = TRUE),
    SD_Length = sd(text_length, na.rm = TRUE)
  )

kable(length_summary, digits = 1, 
      caption = "Text Length Summary by Model Signature")
```

## Statistical Test
```{r q2_test}
# Separate AI vs Non-AI posts
ai_lengths <- df %>%
  filter(model_signature == "GPT-like") %>%
  pull(text_length)

human_lengths <- df %>%
  filter(model_signature != "GPT-like") %>%
  pull(text_length)

# Use Wilcoxon test (safe for non-normal distributions)
length_test <- wilcox.test(ai_lengths, human_lengths)

cat("Wilcoxon Rank-Sum Test\n")
cat("W statistic:", round(length_test$statistic, 4), "\n")
cat("P-value:", format.pval(length_test$p.value, digits = 4), "\n")

if (length_test$p.value < 0.05) {
  cat("\n✓ Result: There IS a statistically significant difference\n")
  cat("  in post length between AI-generated and human posts (p < 0.05)\n")
} else {
  cat("\n✗ Result: There is NO statistically significant difference\n")
  cat("  in post length between AI-generated and human posts (p >= 0.05)\n")
}
```

## Visualization
```{r q2_viz, fig.height=7}
ggplot(df, aes(x = model_signature, y = text_length, fill = model_signature)) +
  geom_boxplot(alpha = 0.8) +
  labs(
    title = "Post Length by Content Source",
    subtitle = "Comparison of AI-generated vs other model signatures",
    x = "Content Source",
    y = "Post Length (Characters)"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    legend.position = "none"
  )
```

**Key Findings**
```{r q2_findings, echo=FALSE}
ai_mean <- mean(ai_lengths, na.rm = TRUE)
human_mean <- mean(human_lengths, na.rm = TRUE)
mean_diff <- ai_mean - human_mean
```

- **Average AI-generated post length:** `r round(ai_mean, 1)` characters  
- **Average human post length:** `r round(human_mean, 1)` characters  

- **Difference in mean length:** `r round(mean_diff, 1)` characters  

- **Statistical significance:**  
  `r ifelse(length_test$p.value < 0.05, "YES", "NO")`  
  *(p = `r round(length_test$p.value, 4)`)*

# Research Question 3: AI-Generated Content and Sentiment

**Question:** Does AI-generated content receive different sentiment scores compared to human posts?

## Model Signature Sentiment Score Table
```{r q3_table}
sentiment_summary <- df %>%
  group_by(model_signature) %>%
  summarise(
    Count = n(),
    Mean_Sentiment = mean(sentiment_score, na.rm = TRUE),
    Median_Sentiment = median(sentiment_score, na.rm = TRUE),
    SD_Sentiment = sd(sentiment_score, na.rm = TRUE)
  )

kable(sentiment_summary, digits = 2,
      caption = "Sentiment Score Summary by Content Source")
```

## Misinformation Percentages Table
```{r q3_rates}
misinfo_rates <- df %>%
  filter(is_misinformation == "Misinformation") %>%
  count(model_signature) %>%
  mutate(
    Total = sum(n),
    Percentage = (n / Total) * 100
  )

kable(misinfo_rates, digits = 1,
      caption = "Percentage of Misinformation by Content Source")
```

**Interpretation:** This table shows what proportion of all misinformation comes from each content source.

## Statistical Test

```{r q3_test}
# Separate AI vs Human sentiment scores
ai_sentiment <- df %>%
  filter(model_signature == "GPT-like") %>%
  pull(sentiment_score)

human_sentiment <- df %>%
  filter(model_signature != "GPT-like") %>%
  pull(sentiment_score)

# Wilcoxon rank-sum test
sentiment_test <- wilcox.test(ai_sentiment, human_sentiment)

cat("Wilcoxon Rank-Sum Test (AI vs Human Sentiment)\n")
cat("===========================================\n")
cat("W statistic:", round(sentiment_test$statistic, 4), "\n")
cat("P-value:", format.pval(sentiment_test$p.value, digits = 4), "\n")

if (sentiment_test$p.value < 0.05) {
  cat("\n✓ Result: There IS a statistically significant difference\n")
  cat("  in sentiment scores between AI and human posts (p < 0.05)\n")
} else {
  cat("\n✗ Result: There is NO statistically significant difference\n")
  cat("  in sentiment scores between AI and human posts (p >= 0.05)\n")
}
```

## Visualization
```{r q3_viz, fig.height=7}
ggplot(df, aes(x = model_signature, y = sentiment_score, fill = model_signature)) +
  geom_boxplot(alpha = 0.8) +
  labs(
    title = "Sentiment Scores by Content Source",
    subtitle = "Comparison of AI-generated vs human posts",
    x = "Content Source",
    y = "Sentiment Score"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    legend.position = "none"
  )
```

**Key Findings**
```{r q3_findings, echo=FALSE}
ai_mean_sentiment <- mean(ai_sentiment, na.rm = TRUE)
human_mean_sentiment <- mean(human_sentiment, na.rm = TRUE)
sentiment_diff <- ai_mean_sentiment - human_mean_sentiment
```

- **Average AI-generated sentiment score:** `r round(ai_mean_sentiment, 2)`  
- **Average human sentiment score:** `r round(human_mean_sentiment, 2)`  
- **Difference in mean sentiment:** `r round(sentiment_diff, 2)`  
- **Statistical significance:**  
  `r ifelse(sentiment_test$p.value < 0.05, "YES", "NO")`  
  *(p = `r round(sentiment_test$p.value, 4)`)* 

# Research Question 4: AI-Generated Content and Misinformation

**Question:** Are misinformation posts more likely to come from AI-generated content compared to legitimate posts?

```{r simplier}
# Create a simpler AI vs non-AI flag

df <- df %>%
mutate(ai_generated = ifelse(model_signature == "GPT-like",
"AI-generated",
"Non-AI / Unknown"))

df$ai_generated <- factor(df$ai_generated,
levels = c("AI-generated", "Non-AI / Unknown"))
```


```{r tableAI}

# Contingency table of AI status by misinformation

ai_table <- table(df$ai_generated, df$is_misinformation)

kable(ai_table,
caption = "Posts by AI-generation status and misinformation label")

```

```{r ai_misinfo_rates}
# Misinformation vs legitimate percentages within each AI group

ai_props <- df %>%
group_by(ai_generated, is_misinformation) %>%
summarise(Count = n(), .groups = "drop") %>%
group_by(ai_generated) %>%
mutate(Total = sum(Count),
Percentage = 100 * Count / Total)

kable(ai_props,
digits = 1,
caption = "Percentage of misinformation vs legitimate posts by AI status")

```

```{r chi square}
# Chi-square test of independence

chi_ai <- chisq.test(ai_table)

cat("Chi-Square Test of Independence (AI-generated x Misinformation)\n")
cat("================================================================\n")
cat("Chi-square statistic:", round(chi_ai$statistic, 4), "\n")
cat("Degrees of freedom:", chi_ai$parameter, "\n")
cat("P-value:", format.pval(chi_ai$p.value, digits = 4), "\n")
```


```{r barchart-percentage}
# Bar chart of percentages

ai_viz <- ai_props

ggplot(ai_viz,
aes(x = ai_generated,
y = Percentage,
fill = is_misinformation)) +
geom_col(position = "dodge", alpha = 0.85, width = 0.7) +
geom_text(aes(label = paste0(round(Percentage, 1), "%")),
position = position_dodge(width = 0.7),
vjust = -0.4,
size = 4,
fontface = "bold") +
labs(title = "Share of Misinformation vs Legitimate Posts",
subtitle = "Broken down by AI-generated vs Non-AI/Unknown content",
x = "Content type",
y = "Percentage of posts",
fill = "Post type") +
theme_minimal(base_size = 12) +
theme(plot.title = element_text(face = "bold", size = 16),
legend.position = "bottom")
```

```{r pull rates}
# Pull out just the misinformation rates

ai_misinfo <- ai_props %>%
filter(is_misinformation == "Misinformation")

ai_rate_ai  <- ai_misinfo$Percentage[ai_misinfo$ai_generated == "AI-generated"]
ai_rate_non <- ai_misinfo$Percentage[ai_misinfo$ai_generated == "Non-AI / Unknown"]
```

# Research Question 5: Toxicity Levels

**Question:** Do misinformation posts show higher toxicity levels than legitimate posts?

## Summary Statistics

```{r q5_summary}
# Calculate summary statistics for toxicity by type
toxicity_summary <- df %>%
  group_by(is_misinformation) %>%
  summarise(
    Mean = mean(toxicity_score),
    Median = median(toxicity_score),
    SD = sd(toxicity_score),
    Min = min(toxicity_score),
    Max = max(toxicity_score),
    Count = n()
  )

kable(toxicity_summary, digits = 3, caption = "Toxicity Score Statistics by Post Type")
```

**Interpretation:** The table above shows the descriptive statistics for toxicity scores. Toxicity scores range from 0 (not toxic) to 1 (very toxic).

## Statistical Test

```{r q5_test}
# Perform t-test
t_test_toxicity <- t.test(toxicity_score ~ is_misinformation, data = df)

# Display results
cat("Independent Samples T-Test\n")
cat("==========================\n")
cat("T-statistic:", round(t_test_toxicity$statistic, 4), "\n")
cat("P-value:", format.pval(t_test_toxicity$p.value, digits = 4), "\n")
cat("95% Confidence Interval:", round(t_test_toxicity$conf.int[1], 4), 
    "to", round(t_test_toxicity$conf.int[2], 4), "\n")
cat("\nMean difference (Legitimate - Misinformation):", 
    round(diff(t_test_toxicity$estimate), 4), "\n")

if (t_test_toxicity$p.value < 0.05) {
  cat("\n✓ Result: There IS a statistically significant difference in toxicity (p < 0.05)\n")
} else {
  cat("\n✗ Result: There is NO statistically significant difference in toxicity (p >= 0.05)\n")
}
```

## Visualization

```{r q5_viz, fig.height=7}
# Create boxplot
p1 <- ggplot(df, aes(x = is_misinformation, y = toxicity_score, 
                     fill = is_misinformation)) +
  geom_boxplot(alpha = 0.7, outlier.shape = 1) +
  geom_jitter(alpha = 0.2, width = 0.2, size = 1) +
  scale_fill_manual(values = c("Legitimate" = "#4CAF50", 
                                "Misinformation" = "#F44336")) +
  labs(title = "Toxicity Levels: Misinformation vs Legitimate Posts",
       subtitle = paste0("Mean Toxicity: Legitimate = ", 
                        round(toxicity_summary$Mean[1], 3),
                        ", Misinformation = ", 
                        round(toxicity_summary$Mean[2], 3)),
       x = "Post Type",
       y = "Toxicity Score (0-1)") +
  theme_minimal(base_size = 12) +
  theme(legend.position = "none",
        plot.title = element_text(face = "bold", size = 16),
        plot.subtitle = element_text(size = 12))

print(p1)
```

**Key Findings:**

- Legitimate posts have a mean toxicity of **`r round(toxicity_summary$Mean[1], 3)`**
- Misinformation posts have a mean toxicity of **`r round(toxicity_summary$Mean[2], 3)`**
- The difference is **`r round(abs(toxicity_summary$Mean[2] - toxicity_summary$Mean[1]), 3)`**
- Statistical significance: **`r ifelse(t_test_toxicity$p.value < 0.05, "YES", "NO")`** (p = `r round(t_test_toxicity$p.value, 4)`)

# Research Question 6: 

**Question:** Which country contributes the most misinformation content, and how does that compare to legitimate content?

```{r country_analysis}
country_summary <- df %>%
group_by(country, is_misinformation) %>%
summarise(Count = n(), .groups = "drop") %>%
group_by(country) %>%
mutate(Total = sum(Count),
Percentage = 100 * Count / Total)

kable(country_summary,
digits = 1,
caption = "Misinformation vs Legitimate Posts by Country")
```

```{r most misinfomration}
country_misinfo <- country_summary %>%
filter(is_misinformation == "Misinformation") %>%
arrange(desc(Count))

kable(country_misinfo,
digits = 1,
caption = "Countries Ranked by Misinformation Post Count")
```


```{r stat_test}
country_table <- table(df$country, df$is_misinformation)

chi_country <- chisq.test(country_table)

cat("Chi-Square Test of Independence (Country x Misinformation)\n")
cat("=========================================================\n")
cat("Chi-square statistic:", round(chi_country$statistic, 4), "\n")
cat("Degrees of freedom:", chi_country$parameter, "\n")
cat("P-value:", format.pval(chi_country$p.value, digits = 4), "\n")
```

```{r percentage by country}
misinfo_share_country <- country_summary %>%
filter(is_misinformation == "Misinformation")

ggplot(misinfo_share_country,
aes(x = reorder(country, -Percentage),
y = Percentage)) +
geom_col(alpha = 0.85, width = 0.7, fill = "#F44336") +
geom_text(aes(label = paste0(round(Percentage, 1), "%")),
vjust = -0.4,
size = 4,
fontface = "bold") +
labs(title = "Share of Misinformation Posts by Country",
x = "Country",
y = "Misinformation as % of Country's Total Posts") +
theme_minimal(base_size = 12) +
theme(plot.title = element_text(face = "bold", size = 16))
```

```{r keyf}
top_country <- misinfo_share_country$country[which.max(misinfo_share_country$Count)]
top_country_pct <- misinfo_share_country$Percentage[which.max(misinfo_share_country$Count)]
```

# Research Question 7: Engagement Differences

**Question:** How does engagement (likes, shares, interactions) differ between misinformation and legitimate posts?

## Summary Statistics

```{r q7_summary}
# Calculate engagement statistics
engagement_summary <- df %>%
  group_by(is_misinformation) %>%
  summarise(
    Mean = mean(engagement),
    Median = median(engagement),
    SD = sd(engagement),
    Min = min(engagement),
    Max = max(engagement),
    Q1 = quantile(engagement, 0.25),
    Q3 = quantile(engagement, 0.75),
    Count = n()
  )

kable(engagement_summary, digits = 1, caption = "Engagement Statistics by Post Type", 
      format.args = list(big.mark = ","))
```

**Interpretation:** Engagement metrics show the total interactions (likes, shares, comments) for each post. Note the wide range, indicating some posts go viral while others receive minimal attention.

## Statistical Test

```{r q7_test}
# Perform Wilcoxon test (better for skewed distributions)
wilcox_test_engagement <- wilcox.test(engagement ~ is_misinformation, data = df)

# Also perform t-test for completeness
t_test_engagement <- t.test(engagement ~ is_misinformation, data = df)

cat("Wilcoxon Rank Sum Test (Non-parametric)\n")
cat("========================================\n")
cat("W-statistic:", wilcox_test_engagement$statistic, "\n")
cat("P-value:", format.pval(wilcox_test_engagement$p.value, digits = 4), "\n")

cat("\n\nIndependent Samples T-Test (Parametric)\n")
cat("========================================\n")
cat("T-statistic:", round(t_test_engagement$statistic, 4), "\n")
cat("P-value:", format.pval(t_test_engagement$p.value, digits = 4), "\n")

if (wilcox_test_engagement$p.value < 0.05) {
  cat("\n✓ Result: There IS a statistically significant difference in engagement (p < 0.05)\n")
} else {
  cat("\n✗ Result: There is NO statistically significant difference in engagement (p >= 0.05)\n")
}
```

## Visualizations

```{r q7_viz1, fig.height=7}
# Boxplot with jittered points
p2 <- ggplot(df, aes(x = is_misinformation, y = engagement, 
                     fill = is_misinformation)) +
  geom_boxplot(alpha = 0.7, outlier.shape = NA) +
  geom_jitter(alpha = 0.3, width = 0.2, size = 1.5) +
  scale_fill_manual(values = c("Legitimate" = "#4CAF50", 
                                "Misinformation" = "#F44336")) +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Engagement Distribution: Misinformation vs Legitimate Posts",
       subtitle = paste0("Median Engagement: Legitimate = ", 
                        scales::comma(round(engagement_summary$Median[1], 0)),
                        ", Misinformation = ", 
                        scales::comma(round(engagement_summary$Median[2], 0))),
       x = "Post Type",
       y = "Engagement (likes, shares, interactions)") +
  theme_minimal(base_size = 12) +
  theme(legend.position = "none",
        plot.title = element_text(face = "bold", size = 16),
        plot.subtitle = element_text(size = 12))

print(p2)
```

```{r q7_viz2, fig.height=6}
# Bar chart comparing means
engagement_means <- df %>%
  group_by(is_misinformation) %>%
  summarise(Mean_Engagement = mean(engagement))

p2b <- ggplot(engagement_means, aes(x = is_misinformation, y = Mean_Engagement, 
                                    fill = is_misinformation)) +
  geom_bar(stat = "identity", alpha = 0.8, width = 0.6) +
  geom_text(aes(label = scales::comma(round(Mean_Engagement, 0))), 
            vjust = -0.5, fontface = "bold", size = 5) +
  scale_fill_manual(values = c("Legitimate" = "#4CAF50", 
                                "Misinformation" = "#F44336")) +
  scale_y_continuous(labels = scales::comma, expand = expansion(mult = c(0, 0.1))) +
  labs(title = "Average Engagement by Post Type",
       x = "Post Type",
       y = "Average Engagement") +
  theme_minimal(base_size = 12) +
  theme(legend.position = "none",
        plot.title = element_text(face = "bold", size = 16))

print(p2b)
```

**Key Findings:**

- Legitimate posts have a median engagement of **`r scales::comma(round(engagement_summary$Median[1], 0))`**
- Misinformation posts have a median engagement of **`r scales::comma(round(engagement_summary$Median[2], 0))`**
- The difference is **`r scales::comma(round(abs(engagement_summary$Median[2] - engagement_summary$Median[1]), 0))`**
- Statistical significance: **`r ifelse(wilcox_test_engagement$p.value < 0.05, "YES", "NO")`** (p = `r round(wilcox_test_engagement$p.value, 4)`)

## Research Question 8: 

**Question:**  Are certain sentiment trends (negative, neutral, positive) more common in misinformation posts?

```{r sentiment cate.}
library(dplyr)

df <- df %>%
mutate(sentiment_category = case_when(
sentiment_score <= -0.2 ~ "Negative",
sentiment_score >=  0.2 ~ "Positive",
TRUE                    ~ "Neutral"
))

df$sentiment_category <- factor(df$sentiment_category,
levels = c("Negative", "Neutral", "Positive"))
```


```{r ctable_percentage}
library(knitr)

sentiment_summary <- df %>%
group_by(sentiment_category, is_misinformation) %>%
summarise(Count = n(), .groups = "drop") %>%
group_by(sentiment_category) %>%
mutate(Total = sum(Count),
Percentage = 100 * Count / Total)

kable(sentiment_summary,
digits = 1,
caption = "Misinformation vs Legitimate Posts by Sentiment Category")
```



```{r sentiment_mis}
sentiment_table <- table(df$sentiment_category, df$is_misinformation)

chi_sentiment <- chisq.test(sentiment_table)

cat("Chi-Square Test of Independence (Sentiment x Misinformation)\n")
cat("===========================================================\n")
cat("Chi-square statistic:", round(chi_sentiment$statistic, 4), "\n")
cat("Degrees of freedom:", chi_sentiment$parameter, "\n")
cat("P-value:", format.pval(chi_sentiment$p.value, digits = 4), "\n")
```


```{r pltx}
library(ggplot2)

ggplot(sentiment_summary,
aes(x = sentiment_category,
y = Percentage,
fill = is_misinformation)) +
geom_col(position = "dodge", alpha = 0.85, width = 0.7) +
geom_text(aes(label = paste0(round(Percentage, 1), "%")),
position = position_dodge(width = 0.7),
vjust = -0.4,
size = 4,
fontface = "bold") +
labs(title = "Misinformation vs Legitimate Posts by Sentiment Category",
x = "Sentiment Category",
y = "Percentage within Each Sentiment Group",
fill = "Post Type") +
theme_minimal(base_size = 12) +
theme(plot.title = element_text(face = "bold", size = 16),
legend.position = "bottom")
```


```{r finalkeyfinds}
sent_misinfo <- sentiment_summary %>%
filter(is_misinformation == "Misinformation") %>%
arrange(desc(Percentage))

top_sent <- sent_misinfo$sentiment_category[1]
top_sent_pct <- sent_misinfo$Percentage[1]
```

# Research Question 9: Verified Users and Misinformation

**Question:** Do verified users spread misinformation at a higher or lower rate than unverified users?

## Contingency Table

```{r q9_table}
# Create contingency table
verification_table <- table(df$author_verified, df$is_misinformation)
rownames(verification_table) <- c("Unverified (0)", "Verified (1)")

kable(verification_table, caption = "Posts by Verification Status and Type")
```

## Misinformation Rates

```{r q9_rates}
# Calculate proportions
verification_props <- df %>%
  group_by(author_verified, is_misinformation) %>%
  summarise(Count = n(), .groups = 'drop') %>%
  group_by(author_verified) %>%
  mutate(Total = sum(Count),
         Percentage = (Count / Total) * 100)

# Extract misinformation rates
misinfo_rates <- verification_props %>%
  filter(is_misinformation == "Misinformation") %>%
  mutate(Verified_Status = ifelse(author_verified == 1, "Verified", "Unverified")) %>%
  select(Verified_Status, Count, Total, Percentage)

kable(misinfo_rates, digits = 1, caption = "Misinformation Rate by Verification Status")
```

**Interpretation:** This table shows what percentage of posts from each user type (verified vs. unverified) are misinformation.

## Statistical Test

```{r q9_test}
# Chi-square test
chi_test <- chisq.test(verification_table)

cat("Chi-Square Test of Independence\n")
cat("================================\n")
cat("Chi-square statistic:", round(chi_test$statistic, 4), "\n")
cat("Degrees of freedom:", chi_test$parameter, "\n")
cat("P-value:", format.pval(chi_test$p.value, digits = 4), "\n")

# Calculate effect size (Cramér's V)
cramers_v <- sqrt(chi_test$statistic / (nrow(df) * (min(dim(verification_table)) - 1)))
cat("Effect size (Cramér's V):", round(cramers_v, 4), "\n")

if (chi_test$p.value < 0.05) {
  cat("\n✓ Result: There IS a statistically significant association between\n")
  cat("  verification status and misinformation spread (p < 0.05)\n")
} else {
  cat("\n✗ Result: There is NO statistically significant association between\n")
  cat("  verification status and misinformation spread (p >= 0.05)\n")
}
```

## Visualizations

```{r q9_viz1, fig.height=7}
# Prepare data for visualization
verification_viz <- df %>%
  mutate(Verified = factor(author_verified, 
                           levels = c(0, 1), 
                           labels = c("Unverified", "Verified"))) %>%
  group_by(Verified, is_misinformation) %>%
  summarise(Count = n(), .groups = 'drop') %>%
  group_by(Verified) %>%
  mutate(Percentage = (Count / sum(Count)) * 100)

# Percentage bar chart
p3 <- ggplot(verification_viz, aes(x = Verified, y = Percentage, 
                                   fill = is_misinformation)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8, width = 0.7) +
  geom_text(aes(label = paste0(round(Percentage, 1), "%")), 
            position = position_dodge(width = 0.7), 
            vjust = -0.5, fontface = "bold", size = 4) +
  scale_fill_manual(values = c("Legitimate" = "#4CAF50", 
                                "Misinformation" = "#F44336")) +
  labs(title = "Misinformation Spread by User Verification Status",
       subtitle = "Percentage of posts that are misinformation vs legitimate",
       x = "User Verification Status",
       y = "Percentage of Posts (%)",
       fill = "Post Type") +
  theme_minimal(base_size = 12) +
  theme(plot.title = element_text(face = "bold", size = 16),
        plot.subtitle = element_text(size = 12),
        legend.position = "bottom",
        legend.title = element_text(face = "bold"))

print(p3)
```

```{r q9_viz2, fig.height=6}
# Raw counts bar chart
p3b <- ggplot(verification_viz, aes(x = Verified, y = Count, 
                                    fill = is_misinformation)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8, width = 0.7) +
  geom_text(aes(label = Count), 
            position = position_dodge(width = 0.7), 
            vjust = -0.5, fontface = "bold", size = 4) +
  scale_fill_manual(values = c("Legitimate" = "#4CAF50", 
                                "Misinformation" = "#F44336")) +
  labs(title = "Raw Counts: Posts by Verification Status and Type",
       x = "User Verification Status",
       y = "Number of Posts",
       fill = "Post Type") +
  theme_minimal(base_size = 12) +
  theme(plot.title = element_text(face = "bold", size = 16),
        legend.position = "bottom",
        legend.title = element_text(face = "bold"))

print(p3b)
```

**Key Findings:**

```{r q9_findings, echo=FALSE}
verified_misinfo_rate <- misinfo_rates$Percentage[misinfo_rates$Verified_Status == "Verified"]
unverified_misinfo_rate <- misinfo_rates$Percentage[misinfo_rates$Verified_Status == "Unverified"]
```

- **Verified users:** `r round(verified_misinfo_rate, 1)`% of their posts are misinformation
- **Unverified users:** `r round(unverified_misinfo_rate, 1)`% of their posts are misinformation
- **Difference:** `r round(abs(verified_misinfo_rate - unverified_misinfo_rate), 1)` percentage points
- **Statistical significance:** `r ifelse(chi_test$p.value < 0.05, "YES", "NO")` (p = `r round(chi_test$p.value, 4)`)

---